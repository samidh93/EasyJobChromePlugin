var A=Object.defineProperty,b=Object.defineProperties;var E=Object.getOwnPropertyDescriptors;var g=Object.getOwnPropertySymbols;var v=Object.prototype.hasOwnProperty,I=Object.prototype.propertyIsEnumerable;var f=(e,o,r)=>o in e?A(e,o,{enumerable:!0,configurable:!0,writable:!0,value:r}):e[o]=r,d=(e,o)=>{for(var r in o||(o={}))v.call(o,r)&&f(e,r,o[r]);if(g)for(var r of g(o))I.call(o,r)&&f(e,r,o[r]);return e},h=(e,o)=>b(e,E(o));chrome.runtime.onInstalled.addListener(()=>{console.log("Job Tracker Extension Installed")});var l=!1,y=null,w=null;chrome.runtime.onMessage.addListener((e,o,r)=>{if(console.log("Background received message:",e),e.action==="startAutoApply")return k(e,r),!0;if(e.action==="stopAutoApply")return S(e,r),!0;if(e.action==="testOllamaConnection")return p().then(a=>{r(a)}).catch(a=>{r({success:!1,error:a.message})}),!0;if(e.action==="callOllama"){let a=e.endpoint||"generate",s=e.data||{};return O(a,s).then(n=>{r(n)}).catch(n=>{r({success:!1,error:n.message})}),!0}else{if(e.action==="testOllama")return p().then(a=>{r(a)}).catch(a=>{r({success:!1,error:a.message})}),!0;if(e.action==="getAutoApplyState")return r({success:!0,isRunning:l}),!0}r({success:!1,error:"Unknown action"})});async function k(e,o){try{if(console.log("Starting auto apply with data:",e),!e.loginData||!e.loginData.username)throw new Error("Login data required");if(!e.aiSettings||!e.aiSettings.provider||!e.aiSettings.model)throw new Error("AI settings required");y=e.loginData,w=e.aiSettings,l=!0,await x(e.aiSettings);let r=await chrome.tabs.query({active:!0,currentWindow:!0});if(r.length>0){let a=r[0].id;if(!r[0].url.includes("linkedin.com"))throw new Error("Please navigate to LinkedIn jobs page first");chrome.tabs.sendMessage(a,{action:"startAutoApply",userData:y,aiSettings:w},s=>{chrome.runtime.lastError?(console.error("Error sending message to content script:",chrome.runtime.lastError),o({success:!1,error:"Failed to communicate with LinkedIn page. Please refresh the page and try again."})):(console.log("Content script response:",s),o({success:!0,message:"Auto apply started successfully"}))})}else throw new Error("No active tab found")}catch(r){console.error("Error starting auto apply:",r),l=!1,o({success:!1,error:r.message})}}async function S(e,o){try{console.log("Stopping auto apply");let r=await chrome.tabs.query({active:!0,currentWindow:!0});if(r.length>0){let a=r[0].id;chrome.tabs.sendMessage(a,{action:"stopAutoApply"},s=>{chrome.runtime.lastError?(console.error("Error sending stop message to content script:",chrome.runtime.lastError),l=!1,o({success:!0,message:"Auto apply stopped (content script communication error)"})):s&&s.success?(console.log("Auto apply stopped successfully"),l=!1,o({success:!0,message:"Auto apply stopped"})):(console.error("Content script failed to stop auto apply:",s==null?void 0:s.error),l=!1,o({success:!0,message:"Auto apply stopped (with content script error)"}))})}else l=!1,o({success:!0,message:"Auto apply stopped (no active tab)"})}catch(r){console.error("Error stopping auto apply:",r),l=!1,o({success:!1,error:r.message})}}async function x(e){if(console.log("Testing AI connection:",e),e.provider==="ollama"){let o=await p();if(!o.success)throw new Error("Ollama connection failed: ".concat(o.error));console.log("Ollama connection successful")}else{if(!e.apiKey)throw new Error("API key required for ".concat(e.provider));console.log("AI settings validated for ".concat(e.provider))}}async function p(){try{console.log("Testing Ollama connection...");let o=await O("chat",{model:"qwen2.5:3b",messages:[{role:"system",content:"You are a helpful AI assistant."},{role:"user",content:"Hello, are you working?"}],stream:!1});if(o.success)return console.log("Ollama chat test successful:",o.data),{success:!0,data:{version:o.data.model,response:o.data.message.content,port:11434}};throw new Error(o.error||"Unknown error from Ollama")}catch(e){return console.error("Ollama connection failed:",e),{success:!1,error:e.message,details:e.stack,troubleshooting:"Please make sure Ollama is running on your computer. Try running 'ollama serve' in your terminal."}}}async function O(e,o){var r,a;try{console.log("Making Ollama API call to ".concat(e,":"),o);let s=11434;console.log("Using Ollama port: ".concat(s));let n=h(d({},o),{stream:!1}),i=await fetch("http://localhost:".concat(s,"/api/").concat(e),{method:"POST",headers:{"Content-Type":"application/json",Accept:"application/json","Access-Control-Allow-Origin":"*"},body:JSON.stringify(n)});if(!i.ok){let c=await i.text();throw console.error("Ollama API error response:",{status:i.status,statusText:i.statusText,body:c}),new Error("HTTP error! status: ".concat(i.status,", details: ").concat(c))}let m=await i.text(),t;try{t=JSON.parse(m)}catch(c){console.warn("JSON parse error:",c.message),console.log("Response text:",m.substring(0,200)+"...");try{let u=m.match(/\{[\s\S]*\}/);if(u)t=JSON.parse(u[0]),console.log("Successfully extracted JSON from response");else throw new Error("Couldn't find valid JSON object in response")}catch(u){throw console.error("Failed to extract JSON:",u),new Error("Invalid JSON response from Ollama: ".concat(c.message))}}if(console.log("Ollama API call successful:",t),e==="chat"){if(!t||!t.message||!t.message.content)if(console.error("Unexpected chat response structure from Ollama:",t),t&&typeof t=="object")t={message:{content:((r=t.message)==null?void 0:r.content)||t.content||t.text||t.response||""||"No content found in response"},model:t.model||"unknown"},console.log("Constructed fallback response:",t);else throw new Error("Invalid chat response format from Ollama")}else if(e==="generate"){if(!t||typeof t.response!="string")if(console.error("Unexpected generate response structure from Ollama:",t),t&&typeof t=="object")t={response:t.response||t.content||t.text||((a=t.message)==null?void 0:a.content)||""||"No response found in result",model:t.model||"unknown"},console.log("Constructed fallback generate response:",t);else throw new Error("Invalid generate response format from Ollama")}else if(e==="embeddings"){if(!t||!t.embedding||!Array.isArray(t.embedding))throw console.error("Unexpected embeddings response structure from Ollama:",t),new Error("Invalid embeddings response format from Ollama")}else if(!t)throw console.error("Empty response from Ollama for endpoint ".concat(e,":"),t),new Error("Invalid response format from Ollama for ".concat(e));return{success:!0,data:t}}catch(s){console.error("Ollama API call failed (".concat(e,"):"),s);let n="Please make sure Ollama is running on your computer. Try running 'ollama serve' in your terminal.";return s.name==="AbortError"?n+=" The request timed out - your model might be too large or your computer too slow.":s.message.includes("Failed to fetch")?n+=" Your computer cannot connect to Ollama. Make sure it's running and not blocked by a firewall.":(s.message.includes("Invalid response format")||s.message.includes("JSON"))&&(n+=" Ollama returned an unexpected response format. You might need to update Ollama to a newer version."),{success:!1,error:s.message,details:s.stack,troubleshooting:n}}}
